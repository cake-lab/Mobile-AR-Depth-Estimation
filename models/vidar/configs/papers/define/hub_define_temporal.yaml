arch:
    model:
        file: perceiver/DefineInferenceModel
        use_pose_noise: []
        use_virtual_cameras: []
        virtual_cameras_eval: False
        use_virtual_rgb: False
        augment_canonical: False
        encode_train: all
        encode_eval: all
        decode_train: all
        decode_eval: all
        decode_encodes: False
        task_weights: [1.0,1.0]
        scale_loss: True
        sample_decoded_queries: 0.0
        network:
            tasks: [depth]
            depth_range: [0.1,10.]
            image_shape: [128,192]
            num_bands_orig: 20
            num_bands_dirs: 10
            max_resolution_orig: 60
            max_resolution_dirs: 60
            to_world: True
            d_latents: 512
            num_latents: 2048
            hidden_dropout_prob: 0.25
            num_cross_attention_heads: 1
            num_self_attends_per_block: 8
            num_self_attention_heads: 8
            decoder_num_heads: 1
            rgb_feat_dim: 960
            rgb_feat_type: resnet_all
            downsample_encoder: 4
            downsample_decoder: 4
            upsample_convex: 'convex'
            encoder_with_rgb: True
            decoder_with_rgb: False
            output_mode: inv_depth
            sample_encoding_rays: 0
            with_monodepth: False